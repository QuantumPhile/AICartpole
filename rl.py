# -*- coding: utf-8 -*-
"""RL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12PgB3IDwJynHMdcXdrFTLpXjCY8escSm
"""

# Import
!pip install gymnasium[classic-control]
!pip install stable-baselines3
!pip install gym[all]

import gym
from stable_baselines3 import A2C
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.evaluation import evaluate_policy


import gymnasium as gym
import numpy as np
import os

# Import

#Config environnement 
env = gym.make('CartPole-v0')
env = make_vec_env('CartPole-v0', n_envs=4)
env.reset()
#Config environnement

#Agent
model = A2C('MlpPolicy', env, verbose=1)
model.learn(total_timesteps=25000)
model.save("a2c_cartpole")

#Agent

#Evaluate
mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=10)
print(f"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}")
#Evaluate

#Test

obs = env.reset()
while True:
    action, _states = model.predict(obs)
    obs, rewards, dones, info = env.step(action)
    env.close
#Test